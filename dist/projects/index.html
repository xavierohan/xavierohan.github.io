<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="icon" href="/favicon.png" type="image/png">
    <link rel="icon" href="/favicon.svg" type="image/svg+xml">
    <link rel="apple-touch-icon" href="/apple-touch-icon.png">

    <link rel="canonical" href="https://xavierohan.github.io/projects/">
    <meta name="generator" content="Astro v2.9.1">
    <meta name="msapplication-TileColor" content="#ffffff">

    <title>Projects - Xavier Thomas</title>

    <!-- General Meta Tags -->
    <meta name="title" content="Projects - Xavier Thomas">
    <meta name="description" content="">
    <meta name="author" content="Xavier Thomas">

    <!-- Open Graph / Facebook -->
    <meta property="og:title" content="Projects - Xavier Thomas">
    <meta property="og:description" content="">
    <meta property="og:url" content="https://xavierohan.github.io/projects/">

    <!-- Twitter -->
    <meta property="twitter:title" content="Projects - Xavier Thomas">
    <meta property="twitter:description" content="">
    <meta property="twitter:url" content="https://xavierohan.github.io/projects/">

    
  <link rel="stylesheet" href="/_astro/404.8e5450ac.css" />
<link rel="stylesheet" href="/_astro/index.6d5eb475.css" /><script type="module" src="/_astro/hoisted.7ae76cac.js"></script></head>

  <body class="font-sans">
    <main class=" flex flex-col min-h-full text-c px-4 pt-24 pb-4 md:pb-6">
      <style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event("astro:load"));})();;(()=>{var d;{let h={0:t=>t,1:t=>JSON.parse(t,a),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(JSON.parse(t,a)),5:t=>new Set(JSON.parse(t,a)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(JSON.parse(t)),9:t=>new Uint16Array(JSON.parse(t)),10:t=>new Uint32Array(JSON.parse(t))},a=(t,e)=>{if(t===""||!Array.isArray(e))return e;let[r,n]=e;return r in h?h[r](n):void 0};customElements.get("astro-island")||customElements.define("astro-island",(d=class extends HTMLElement{constructor(){super(...arguments);this.hydrate=async()=>{var o;if(!this.hydrator||!this.isConnected)return;let e=(o=this.parentElement)==null?void 0:o.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let r=this.querySelectorAll("astro-slot"),n={},c=this.querySelectorAll("template[data-astro-template]");for(let s of c){let i=s.closest(this.tagName);i!=null&&i.isSameNode(this)&&(n[s.getAttribute("data-astro-template")||"default"]=s.innerHTML,s.remove())}for(let s of r){let i=s.closest(this.tagName);i!=null&&i.isSameNode(this)&&(n[s.getAttribute("name")||"default"]=s.innerHTML)}let l=this.hasAttribute("props")?JSON.parse(this.getAttribute("props"),a):{};await this.hydrator(this)(this.Component,l,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))}}connectedCallback(){!this.hasAttribute("await-children")||this.firstChild?this.childrenConnectedCallback():new MutationObserver((e,r)=>{r.disconnect(),setTimeout(()=>this.childrenConnectedCallback(),0)}).observe(this,{childList:!0})}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}start(){let e=JSON.parse(this.getAttribute("opts")),r=this.getAttribute("client");if(Astro[r]===void 0){window.addEventListener(`astro:${r}`,()=>this.start(),{once:!0});return}Astro[r](async()=>{let n=this.getAttribute("renderer-url"),[c,{default:l}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),o=this.getAttribute("component-export")||"default";if(!o.includes("."))this.Component=c[o];else{this.Component=c;for(let s of o.split("."))this.Component=this.Component[s]}return this.hydrator=l,this.hydrate},e,this)}attributeChangedCallback(){this.hydrate()}},d.observedAttributes=["props"],d))}})();</script><astro-island uid="16uqmi" data-solid-render-id="s5" component-url="/_astro/Navbar.8c0432d4.js" component-export="default" renderer-url="/_astro/client.c4b1b5bc.js" props="{&quot;activePage&quot;:[0,&quot;projects&quot;],&quot;hasToc&quot;:[0,false]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;Navbar&quot;,&quot;value&quot;:true}" await-children=""><header data-hk="s50-0" class="z-30 w-full h-14 hstack justify-between bg-c font-ui px-4 md:px-5 false false absolute top-0 left-0"><a font-bold text="c-light hover:c-dark" href="/"><span text-lg>Home</span><div i-fa6-solid:angle-right class="prompt inline-block"></div></a><nav hstack space-x-4><a nav-item href="/projects" title="Projects"><div i-ph:flask-duotone class="md:hidden"></div>  <span class="text-active">Projects</span></a><a nav-item href="/writings" title="Writings"><div i-ph:pencil-duotone class="md:hidden"></div>  <span class="lt-md:hidden ">Writings</span></a><!--#--><!--/--></nav></header></astro-island>
      <div class="flex-1 mb-6">
        <div class="prose prose-lg mx-auto">
          
  <h1>Projects</h1>
  <h2 id="revelio-interpreting-and-leveraging-semantic-information-in-diffusion-models"><a aria-hidden="true" tabindex="-1" class="header-anchor" href="#revelio-interpreting-and-leveraging-semantic-information-in-diffusion-models">#</a>Revelio: Interpreting and leveraging semantic information in diffusion models</h2>
<p>We study how rich visual semantic information is represented within various layers and denoising timesteps of different diffusion architectures. We uncover monosemantic interpretable features by leveraging k-sparse autoen- coders (k-SAE). We substantiate our mechanistic interpretations via transfer learning using light-weight classifiers on off-the-shelf diffusion models’ features. On 4 datasets, we demonstrate the effectiveness of diffusion features for representation learning. We provide in-depth analysis of how different diffusion architectures, pre-training datasets, and language model conditioning impacts visual representation granularity, inductive biases, and transfer learning capabilities. Our work is a critical step towards deepening interpretability of black-box diffusion models.</p>
<img src="/img/my_imgs/revelio.png" class="paper-images">
<p>Full Paper: <a href="https://www.arxiv.org/abs/2411.16725" target="_blank" rel="noopener noreferrer">https://www.arxiv.org/abs/2411.16725</a></p>
<p>Code: <a href="https://github.com/revelio-diffusion/revelio" target="_blank" rel="noopener noreferrer">https://github.com/revelio-diffusion/revelio</a></p>
<p>Webpage: <a href="https://revelio-diffusion.github.io/revelio/" target="_blank" rel="noopener noreferrer">https://revelio-diffusion.github.io/revelio/</a></p>
<h2 id="edubotics-core-an-open-source-python-library-for-building-llm-based-applications"><a aria-hidden="true" tabindex="-1" class="header-anchor" href="#edubotics-core-an-open-source-python-library-for-building-llm-based-applications">#</a>edubotics-core: An Open-Source Python Library for Building LLM-based Applications</h2>
<p>edubotics-core is an open-source Python library that allows developers to build LLM-based chatbots efficiently. It provides a comprehensive set of core modules for vector storage, retrieval, processing, with more to come.</p>
<img src="https://github.com/edubotics-ai/.github/blob/main/assets/images/edubot-mascot.png?raw=true" class="paper-images" width="30%" height="30%">
<p><strong>Installation:</strong></p>
<p></p><div class="language-bash"><span class="lang">bash</span><p></p>
<pre><code class="language-bash">pip install edubotics-core
</code></pre>
</div>
<p>Code: <a href="https://github.com/edubotics-ai/edubotics-core" target="_blank" rel="noopener noreferrer">https://github.com/edubotics-ai/edubotics-core</a></p>
<p>Full Documentation: <a href="http://docs.edubotics.ai" target="_blank" rel="noopener noreferrer">http://docs.edubotics.ai</a></p>
<p>Applications built with edubotics-core: <a href="https://github.com/edubotics-ai/edubotics-app" target="_blank" rel="noopener noreferrer">https://github.com/edubotics-ai/edubotics-app</a></p>
<img src="/img/my_imgs/edubotics_1.png" class="paper-images" width="100%" height="100%">
<img src="/img/my_imgs/edubotics_2.png" class="paper-images" width="100%" height="100%"> 
<h2 id="mavic-multimodal-active-learning-for-video-captioning"><a aria-hidden="true" tabindex="-1" class="header-anchor" href="#mavic-multimodal-active-learning-for-video-captioning">#</a>MAViC: Multimodal Active Learning for Video Captioning</h2>
<p>A large number of annotated video-caption pairs are required for training video captioning models, resulting in high annotation costs. Active learning can be instrumental in reducing these annotation requirements. However, active learning for video captioning is challenging because multiple semantically similar captions are valid for a video, resulting in high entropy outputs even for less-informative samples. Moreover, video captioning algorithms are multimodal in nature with a visual encoder and language decoder. Further, the sequential and combinatorial nature of the output makes the problem even more challenging. In this work, we introduce MAViC which leverages our proposed Multimodal Semantics Aware Sequential Entropy (M-SASE) based acquisition function to address the challenges of active learning approaches for video captioning. Our approach integrates semantic similarity and uncertainty of both visual and language dimensions in the acquisition function. Our detailed experiments empirically demonstrate the efficacy of M-SASE for active learning for video captioning and improve on the baselines by a large margin.</p>
<img src="/img/my_imgs/MAVIC.png" class="paper-images" width="100%" height="100%">
<p>Full Paper: <a href="https://arxiv.org/abs/2212.11109" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2212.11109</a></p>
<p> </p>
<h2 id="adaclust-adaptive-methods-for-aggregated-domain-generalization"><a aria-hidden="true" tabindex="-1" class="header-anchor" href="#adaclust-adaptive-methods-for-aggregated-domain-generalization">#</a>AdaClust: Adaptive Methods for Aggregated Domain Generalization</h2>
<p>Domain generalization involves learning a classifier from a heterogeneous collection of training sources such that it generalizes to data drawn from similar unknown target domains, with applications in large-scale learning and personalized inference. In many settings, privacy concerns prohibit obtaining domain labels for the training data samples, and instead only have an aggregated collection of training points. Existing approaches that utilize domain labels to create domain-invariant feature representations are inapplicable in this setting, requiring alternative approaches to learn generalizable classifiers. In this work, we propose a domain-adaptive approach to this problem, which operates in two steps: (a) we cluster training data within a carefully chosen feature space to create pseudo-domains, and (b) using these pseudo-domains we learn a domain-adaptive classifier that makes predictions using information about both the input and the pseudo-domain it belongs to. Our approach achieves state-of-the-art performance on a variety of domain generalization benchmarks without using domain labels whatsoever. Furthermore, we provide novel theoretical guarantees on domain generalization  in using cluster information. Our approach is amenable to ensemble-based methods and provides substantial gains even on large-scale benchmark datasets.</p>
<img src="/img/my_imgs/main_cvpr22_new.jpg" class="paper-images">
<p>Full Paper: <a href="https://arxiv.org/abs/2112.04766" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2112.04766</a></p>
<p>Code: <a href="https://github.com/xavierohan/AdaClust_DomainBed" target="_blank" rel="noopener noreferrer">https://github.com/xavierohan/AdaClust_DomainBed</a></p>
<p> </p>
<h2 id="diversity-vs-recognizability-human-like-generalization-in-one-shot-generative-models"><a aria-hidden="true" tabindex="-1" class="header-anchor" href="#diversity-vs-recognizability-human-like-generalization-in-one-shot-generative-models">#</a>Diversity vs. Recognizability: Human-like generalization in one-shot generative models</h2>
<p>Robust generalization to new concepts has long remained a distinctive feature of human intelligence. However, recent progress in deep generative models has now led to neural architectures capable of synthesizing novel instances of unknown visual concepts from a single training example. Yet, a more precise comparison between these models and humans is not possible because existing performance metrics for generative models (i.e., FID, IS, likelihood) are not appropriate for the one-shot generation scenario. Here, we propose a new framework to evaluate one-shot generative models along two axes: sample recognizability vs. diversity  (i.e., intra-class variability). Using this framework, we perform a systematic evaluation of representative one-shot generative models on the Omniglot handwritten dataset. We first show that GAN-like and VAE-like models fall on opposite ends of the diversity-recognizability space. Extensive analyses of the effect of key model parameters further revealed that spatial attention and context integration have a linear contribution to the diversity-recognizability trade-off. In contrast, disentanglement transports the model along a parabolic curve that could be used to maximize recognizability. Using the diversity-recognizability framework, we were able to identify models and parameters that closely approximate human data.</p>
<div style="display: flex; justify-content: space-between; align-items: center;">
  <img src="/img/my_imgs/Fig_serrelab_resized.png" class="paper-images" width="50%" height="50%">
  <img src="/img/my_imgs/div_vs_rec2.png" class="paper-images" width="50%" height="50%">
</div>
<p>Full Paper: <a href="https://arxiv.org/abs/2205.10370" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2205.10370</a></p>
<p>Code: <a href="https://github.com/serre-lab/diversity_vs_recognizability" target="_blank" rel="noopener noreferrer">https://github.com/serre-lab/diversity_vs_recognizability</a></p>
  
        <h3>Code</h3>
        <div grid="~ cols-1 sm:cols-2 gap-2" py-2>
          <astro-island uid="u9lqX" data-solid-render-id="s0" component-url="/_astro/Project.0081c0fc.js" component-export="default" renderer-url="/_astro/client.c4b1b5bc.js" props="{&quot;project&quot;:[0,{&quot;name&quot;:[0,&quot;revelio&quot;],&quot;link&quot;:[0,&quot;https://github.com/revelio-diffusion/revelio&quot;],&quot;desc&quot;:[0,&quot;Code for \&quot;Revelio, Interpreting and Leveraging Visual Semantic Information in Diffusion Models\&quot;&quot;],&quot;tech&quot;:[1,&quot;[[0,\&quot;i-logos:python\&quot;]]&quot;],&quot;repo&quot;:[0,&quot;revelio-diffusion/revelio&quot;]}]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;Project&quot;,&quot;value&quot;:true}" await-children=""><a data-hk="s00-0" class="relative hstack space-x-5 p-4 !no-underline !text-c" border="~ c hover:transparent" bg="hover:gray-100 dark:hover:gray-600" href="https://github.com/revelio-diffusion/revelio" title="revelio" target="_blank" rel="noopener noreferrer"><div class="flex-auto"><div class="hstack flex-wrap"><div whitespace-nowrap mr-3>revelio</div><div hstack space-x-2><!--#--><span data-hk="s00-1" class="text-xs i-logos:python"></span><!--/--><!--#--><!--/--></div></div><div mt-1 text="sm c-lighter">Code for "Revelio, Interpreting and Leveraging Visual Semantic Information in Diffusion Models"</div></div></a></astro-island><astro-island uid="FPTdk" data-solid-render-id="s1" component-url="/_astro/Project.0081c0fc.js" component-export="default" renderer-url="/_astro/client.c4b1b5bc.js" props="{&quot;project&quot;:[0,{&quot;name&quot;:[0,&quot;edubotics-core&quot;],&quot;link&quot;:[0,&quot;https://github.com/edubotics-ai/edubotics-core&quot;],&quot;desc&quot;:[0,&quot;edubotics-core is an open-source Python library that allows developers to build LLM-based chatbots efficiently. It provides a comprehensive set of core modules for vector storage, retrieval, processing, with more to come.&quot;],&quot;tech&quot;:[1,&quot;[[0,\&quot;i-logos:python\&quot;]]&quot;],&quot;repo&quot;:[0,&quot;edubotics-ai/edubotics-core&quot;]}]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;Project&quot;,&quot;value&quot;:true}" await-children=""><a data-hk="s10-0" class="relative hstack space-x-5 p-4 !no-underline !text-c" border="~ c hover:transparent" bg="hover:gray-100 dark:hover:gray-600" href="https://github.com/edubotics-ai/edubotics-core" title="edubotics-core" target="_blank" rel="noopener noreferrer"><div class="flex-auto"><div class="hstack flex-wrap"><div whitespace-nowrap mr-3>edubotics-core</div><div hstack space-x-2><!--#--><span data-hk="s10-1" class="text-xs i-logos:python"></span><!--/--><!--#--><!--/--></div></div><div mt-1 text="sm c-lighter">edubotics-core is an open-source Python library that allows developers to build LLM-based chatbots efficiently. It provides a comprehensive set of core modules for vector storage, retrieval, processing, with more to come.</div></div></a></astro-island><astro-island uid="ygDqa" data-solid-render-id="s2" component-url="/_astro/Project.0081c0fc.js" component-export="default" renderer-url="/_astro/client.c4b1b5bc.js" props="{&quot;project&quot;:[0,{&quot;name&quot;:[0,&quot;sonar&quot;],&quot;link&quot;:[0,&quot;https://github.com/aidecentralized/sonar&quot;],&quot;desc&quot;:[0,&quot;SONAR - Self-Organizing Network of Aggregated Representations&quot;],&quot;tech&quot;:[1,&quot;[[0,\&quot;i-logos:python\&quot;]]&quot;],&quot;repo&quot;:[0,&quot;aidecentralized/sonar&quot;]}]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;Project&quot;,&quot;value&quot;:true}" await-children=""><a data-hk="s20-0" class="relative hstack space-x-5 p-4 !no-underline !text-c" border="~ c hover:transparent" bg="hover:gray-100 dark:hover:gray-600" href="https://github.com/aidecentralized/sonar" title="sonar" target="_blank" rel="noopener noreferrer"><div class="flex-auto"><div class="hstack flex-wrap"><div whitespace-nowrap mr-3>sonar</div><div hstack space-x-2><!--#--><span data-hk="s20-1" class="text-xs i-logos:python"></span><!--/--><!--#--><!--/--></div></div><div mt-1 text="sm c-lighter">SONAR - Self-Organizing Network of Aggregated Representations</div></div></a></astro-island><astro-island uid="Z644nJ" data-solid-render-id="s3" component-url="/_astro/Project.0081c0fc.js" component-export="default" renderer-url="/_astro/client.c4b1b5bc.js" props="{&quot;project&quot;:[0,{&quot;name&quot;:[0,&quot;AdaClust_DomainBed&quot;],&quot;link&quot;:[0,&quot;https://github.com/xavierohan/AdaClust_DomainBed&quot;],&quot;desc&quot;:[0,&quot;Code for AdaClust, Adaptive Methods for Aggregated Domain Generalization&quot;],&quot;tech&quot;:[1,&quot;[[0,\&quot;i-logos:python\&quot;]]&quot;],&quot;repo&quot;:[0,&quot;xavierohan/AdaClust_DomainBed&quot;]}]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;Project&quot;,&quot;value&quot;:true}" await-children=""><a data-hk="s30-0" class="relative hstack space-x-5 p-4 !no-underline !text-c" border="~ c hover:transparent" bg="hover:gray-100 dark:hover:gray-600" href="https://github.com/xavierohan/AdaClust_DomainBed" title="AdaClust_DomainBed" target="_blank" rel="noopener noreferrer"><div class="flex-auto"><div class="hstack flex-wrap"><div whitespace-nowrap mr-3>AdaClust_DomainBed</div><div hstack space-x-2><!--#--><span data-hk="s30-1" class="text-xs i-logos:python"></span><!--/--><!--#--><!--/--></div></div><div mt-1 text="sm c-lighter">Code for AdaClust, Adaptive Methods for Aggregated Domain Generalization</div></div></a></astro-island><astro-island uid="Z1TFXLN" data-solid-render-id="s4" component-url="/_astro/Project.0081c0fc.js" component-export="default" renderer-url="/_astro/client.c4b1b5bc.js" props="{&quot;project&quot;:[0,{&quot;name&quot;:[0,&quot;diversity_vs_recognizability&quot;],&quot;link&quot;:[0,&quot;https://github.com/serre-lab/diversity_vs_recognizability&quot;],&quot;desc&quot;:[0,&quot;Code for Diversity vs. Recognizability, Human-like generalization in one-shot generative models&quot;],&quot;tech&quot;:[1,&quot;[[0,\&quot;i-logos:python\&quot;]]&quot;],&quot;repo&quot;:[0,&quot;serre-lab/diversity_vs_recognizability&quot;]}]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;Project&quot;,&quot;value&quot;:true}" await-children=""><a data-hk="s40-0" class="relative hstack space-x-5 p-4 !no-underline !text-c" border="~ c hover:transparent" bg="hover:gray-100 dark:hover:gray-600" href="https://github.com/serre-lab/diversity_vs_recognizability" title="diversity_vs_recognizability" target="_blank" rel="noopener noreferrer"><div class="flex-auto"><div class="hstack flex-wrap"><div whitespace-nowrap mr-3>diversity_vs_recognizability</div><div hstack space-x-2><!--#--><span data-hk="s40-1" class="text-xs i-logos:python"></span><!--/--><!--#--><!--/--></div></div><div mt-1 text="sm c-lighter">Code for Diversity vs. Recognizability, Human-like generalization in one-shot generative models</div></div></a></astro-island>
        </div>
      
        </div>
      </div>
      <footer class="max-w-content w-full hstack justify-between font-ui mx-auto mt-20 astro-SZ7XMLTE" text="xs lg:sm">
  <span text-c-lighter class="astro-SZ7XMLTE">
    <span class="astro-SZ7XMLTE">© Xavier Thomas 2025</span>
  </span>
  <!-- <span hstack space-x-3>
    <a
      class="footer-item"
      href="https://github.com/Renovamen/renovamen.github.io"
      title="Source code"
      target="_blank"
      rel="noopener noreferrer"
    >
      <div i-lucide:code-2></div>
      <span lt-sm:hidden>Code</span>
    </a>
    <a
      class="footer-item"
      href="/rss.xml"
      title="RSS"
      target="_blank"
      rel="noopener noreferrer"
    >
      <div i-heroicons:rss-20-solid></div>
      <span lt-sm:hidden>RSS</span>
    </a>
    <a
      class="footer-item"
      href="/sitemap-index.xml"
      title="Sitemap"
      target="_blank"
      rel="noopener noreferrer"
    >
      <div i-bx:map-alt></div>
      <span lt-sm:hidden>Sitemap</span>
    </a>
  </span> -->
</footer>
    </main>
  </body></html>