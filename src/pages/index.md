---
layout: ../layouts/About.astro
name: Xavier Thomas
subname: (Rohan)
avatar: img/my_imgs/prof_pic.jpg
socials:
  - icon: "fas fa-envelope"
    link: "mailto:xavierohan1@gmail.com"
  - icon: "fab fa-github"
    link: https://github.com/xavierohan
  - icon: "fab fa-linkedin"
    link: https://www.linkedin.com/in/xavierohan
  - icon: "i-academicons:google-scholar"
    link: https://scholar.google.com/citations?user=U5Qor54AAAAJ
  - icon: "fab fa-twitter"
    link: https://twitter.com/xavierohan
---

ðŸ‘‹ Hi! I'm currently a Grad Student at [Boston University](https://www.bu.edu/cs/). I completed my undergrad at [Manipal Institute of Technology, India](https://manipal.edu/mit.html), and had developed a keen interest in all things ML during my first year and was fortunate to gain research experience along the way. Prior to joining BU, I worked with the Content and User Understanding team at ShareChat, and was fortunate to work on projects with the Serre Lab (Brown University), Human Dynamics Group (MIT Media Lab, Massachusetts Institute of Technology), ETS, Montreal and FOR.ai (now Cohere for AI).

At BU, I am fortunate to be advised by [Prof. Deepti Ghadiyaram](https://deeptigp.github.io), and Iâ€™m currently exploring topics in computer vision, with a broad interest in representation learning and generative models.
 
<a href="mailto:xavierohan1@gmail.com" style="color: black;">
  <i class="fas fa-envelope" style="color: black;"></i> Email Me
</a>

---

## Education

<div class="section-container">
<div class="experience-item">
  <div class="experience-content">
    <div class="experience-title">Ph.D. in Computer Science <span class="experience-date-inline">2025 â€“ Present</span></div>
    <div class="experience-title" style="margin-top: 0.25rem; font-weight: normal;">M.S. in Artificial Intelligence <span class="experience-date-inline">2023 â€“ 2025</span></div>
    <div class="experience-org">Boston University</div>
  </div>
</div>

<div class="experience-item">
  <div class="experience-content">
    <div class="experience-title">B.Tech. in Electronics and Instrumentation <span class="experience-date-inline">2018 â€“ 2022</span></div>
    <div class="experience-org">Manipal Institute of Technology <span class="experience-subtitle-inline">Â· Minor in Computational Intelligence</span></div>
  </div>
</div>
</div>

## Research

<div class="section-container">
<div class="publication-item">
  <div class="publication-content">
    <div class="publication-title">Generative Action Tell-Tales: Assessing human motion in synthesized videos</div>
    <div class="publication-authors"><u>Xavier Thomas</u>, Youngsun Lim, Ananya Srinivasan, Audrey Zheng, Deepti Ghadiyaram</div>
    <div class="publication-meta">Under Review Â· <a href="#">Code</a> Â· <a href="https://arxiv.org/abs/2112.04766">Paper</a></div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-content">
    <div class="publication-title">What's in a Latent? Leveraging Diffusion Latent Space for Domain Generalization</div>
    <div class="publication-authors"><u>Xavier Thomas</u>, Deepti Ghadiyaram</div>
    <div class="publication-meta">International Conference on Computer Vision (ICCV), 2025 Â· <a href="https://xthomasbu.github.io/GUIDE/">Code</a> Â· <a href="https://arxiv.org/abs/2503.06698">Paper</a></div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-content">
    <div class="publication-title">Revelio: Interpreting and leveraging semantic information in diffusion models</div>
    <div class="publication-authors">Dahye Kim*, <u>Xavier Thomas</u>*, Deepti Ghadiyaram</div>
    <div class="publication-meta">International Conference on Computer Vision (ICCV), 2025 Â· <a href="https://github.com/revelio-diffusion/revelio">Code</a> Â· <a href="https://www.arxiv.org/abs/2411.16725">Paper</a></div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-content">
    <div class="publication-title">Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models</div>
    <div class="publication-authors">Ketan Suhaas Saichandran*, <u>Xavier Thomas</u>*, Prakhar Kaushik, Deepti Ghadiyaram</div>
    <div class="publication-meta">AI4CC Workshop, IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR), 2025 (oral) Â· <a href="https://ketansuhaas.github.io/scope-diffusers">Code</a> Â· <a href="https://arxiv.org/abs/2503.17794">Paper</a></div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-content">
    <div class="publication-title">Diversity vs. Recognizability: Human-like generalization in one-shot generative models</div>
    <div class="publication-authors">Victor Boutin, Lakshya Singhal, <u>Xavier Thomas</u>, Thomas Serre</div>
    <div class="publication-meta">Neural Information Processing Systems (NeurIPS), 2022 Â· <a href="https://github.com/serre-lab/diversity_vs_recognizability">Code</a> Â· <a href="https://arxiv.org/abs/2205.10370">Paper</a></div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-content">
    <div class="publication-title">Adaptive Methods for Aggregated Domain Generalization</div>
    <div class="publication-authors"><u>Xavier Thomas</u>, Dhruv Mahajan, Alex Pentland, Abhimanyu Dubey</div>
    <div class="publication-meta">Preprint Â· <a href="https://github.com/xavierohan/AdaClust_DomainBed">Code</a> Â· <a href="https://arxiv.org/abs/2112.04766">Paper</a></div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-content">
    <div class="publication-title">MAViC: Multimodal Active Learning for Video Captioning</div>
    <div class="publication-authors">Gyanendra Das, <u>Xavier Thomas</u>, Anant Raj, Vikram Gupta</div>
    <div class="publication-meta">Preprint Â· <a href="https://arxiv.org/abs/2212.11109">Paper</a></div>
  </div>
</div>

For more see <a href="https://scholar.google.com/citations?user=U5Qor54AAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar</a>
</div>

## Experience

<div class="section-container">
<div class="experience-item">
  <div class="experience-image">
    <img src="/img/my_imgs/bu.png" alt="Boston University">
  </div>
  <div class="experience-content">
    <div class="experience-title">Graduate Researcher</div>
    <div class="experience-org">Boston University</div>
    <div class="experience-date">Jun 2024 â€“ Present</div>
    <div class="experience-description">
      <ul class="experience-bullets">
        <li><strong>Vision in Multimodal Large Language Models (MLLMs):</strong> Investigating limitations of visual understanding in MLLMs and developing methods to improve cross-modal alignment for robust multimodal reasoning.</li>
        <li><strong>Evaluation of Video Generation Models:</strong> Designing and implementing novel evaluation metrics to assess human action fidelity, temporal consistency, and motion coherence in generative video models.</li>
        <li><strong>Internal Representations of Diffusion Models:</strong> Analyzing diffusion models as representation learners by probing their intermediate states; demonstrating their effectiveness for downstream tasks such as classification, multi-modal reasoning, and domain generalization.</li>
      </ul>
    </div>
    <div class="experience-advisor">Advisor: <a href="https://deeptigp.github.io">Prof. Deepti Ghadiyaram</a></div>
  </div>
</div>

<div class="experience-item">
  <div class="experience-image">
    <img src="/img/my_imgs/sharechatlogo.png" alt="ShareChat">
  </div>
  <div class="experience-content">
    <div class="experience-title">Machine Learning Engineer Intern</div>
    <div class="experience-org">ShareChat | Content and User Understanding Team</div>
    <div class="experience-date">Jul 2022 â€“ Jun 2023</div>
    <div class="experience-description">
      Integrated advanced computer vision pipelines into production, improving content classification and moderation capabilities on ShareChat (180M+ MAUs) and Moj (160M+ MAUs). Contributed to <strong>MAViC, a Multimodal Active Learning algorithm for Video Captioning</strong> that reduces annotation effort by integrating semantic similarity and uncertainty from visual and language modalities.
    </div>
    <div class="experience-advisor">Manager: <a href="https://www.linkedin.com/in/iamvikramgupta/?originalSubdomain=in">Vikram Gupta</a> | Advisors: <a href="https://anantrajml.github.io/">Prof. Anant Raj</a>, <a href="https://mbzuai.ac.ae/study/faculty/hisham-cholakkal/">Prof. Hisham Cholakkal</a></div>
  </div>
</div>

<div class="experience-item">
  <div class="experience-image">
    <img src="/img/my_imgs/brownlogo.jpeg" alt="Brown University">
  </div>
  <div class="experience-content">
    <div class="experience-title">Research Intern</div>
    <div class="experience-org">Serre Lab, Brown University</div>
    <div class="experience-date">Sep 2021 â€“ May 2022</div>
    <div class="experience-description">
      Developed a <strong>novel evaluation framework for one-shot generative models</strong>, introducing new metrics for recognizability (human interpretability) and diversity (concept coverage) to enable systematic comparisons. Benchmarked 4 representative generative architectures against human performance on the Omniglot dataset.
    </div>
    <div class="experience-advisor">Advisors: <a href="https://serre-lab.clps.brown.edu/person/victor-boutin/">Dr. Victor Boutin</a>, <a href="https://vivo.brown.edu/display/tserre">Prof. Thomas Serre</a></div>
  </div>
</div>

<div class="experience-item">
  <div class="experience-image">
    <img src="/img/my_imgs/medialab.png" alt="MIT Media Lab">
  </div>
  <div class="experience-content">
    <div class="experience-title">Research Assistant</div>
    <div class="experience-org">MIT Media Lab</div>
    <div class="experience-date">Jan 2021 â€“ Nov 2021</div>
    <div class="experience-description">
      Created a <strong>novel algorithm for privacy-preserving domain generalization</strong> that recovers domain information by removing class-specific noise from latent features, enabling the training of robust, domain-adaptive classifiers. Outperformed state-of-the-art methods that require domain supervision on multiple benchmarks.
    </div>
    <div class="experience-advisor">Advisor: <a href="https://ai.facebook.com/people/abhimanyu-dubey/">Dr. Abhimanyu Dubey</a></div>
  </div>
</div>

<div class="experience-item">
  <div class="experience-image">
    <img src="/img/my_imgs/etslogo.png" alt="Ã‰TS MontrÃ©al">
  </div>
  <div class="experience-content">
    <div class="experience-title">Mitacs Globalink Research Intern</div>
    <div class="experience-org">Ã‰cole de technologie supÃ©rieure (Ã‰TS), MontrÃ©al</div>
    <div class="experience-date">Jul 2021 â€“ Sep 2021</div>
    <div class="experience-description">
      Extended <strong>sub-category exploration methods</strong> for Weakly Supervised Semantic Segmentation by clustering image features to generate more accurate pseudo-labels. Designed novel constraint-based refinements to enhance object localization in Class Activation Maps (CAMs), improving mIoU scores on PASCAL VOC 2012.
    </div>
    <div class="experience-advisor">Advisor: <a href="https://josedolz.github.io">Dr. Jose Dolz</a></div>
  </div>
</div>

<div class="experience-item">
  <div class="experience-image">
    <img src="/img/my_imgs/for_ai.jpg" alt="For.ai">
  </div>
  <div class="experience-content">
    <div class="experience-title">Researcher</div>
    <div class="experience-org">FOR.ai (now Cohere For AI)</div>
    <div class="experience-date">Oct 2020 â€“ Aug 2021</div>
    <div class="experience-description">
      Contributed to a <strong>large-scale benchmarking study of Out-of-Distribution (OOD) detection</strong> in computer vision models, establishing baselines for evaluating robustness under distribution shifts. Collaborated with researchers from Google Brain, University of Oxford, and Vector Institute.
    </div>
    <div class="experience-advisor">Advisor: <a href="https://www.cs.toronto.edu/~huang/">Sheldon Huang</a></div>
  </div>
</div>
</div>
